#+title: Linux Audio Stack: From Hardware to Application
#+author: SOV710
#+date: 2025-12-23
#+startup: showall
#+options: toc:2 num:nil

* 前言: 音频子系统的历史包袱与现代统一

Linux 音频系统虽然过去有过很混乱的历史，但是在 2025 快 2026 的今天，实在是没必要再继续被骂了。回顾历史:

** 内核层的统一: ALSA 的最终胜利

早期 Linux 音频驱动有两套框架并存:

- *OSS (Open Sound System)*: 1992 年诞生，最早的 Unix 音频 API，接口简单但功能受限。后来被商业化 (OSS/4Free)，内核社区不满。
- *ALSA (Advanced Linux Sound Architecture)*: 1998 年启动，作为 OSS 的替代品，提供更强的功能 (软件混音、多流、插件系统)。

2002 年，Linux 2.6 内核正式将 ALSA 作为默认音频框架，OSS 被标记为 deprecated。到了 *Linux 4.9 (2016 年)*，OSS 驱动彻底从内核主线移除，只在 ALSA 中保留 =snd-pcm-oss= 兼容层 (通过 =/dev/dsp= 模拟 OSS 接口)。

今天，如果你看到 =/dev/dsp= 或 =/dev/audio=，那是 ALSA 的 OSS 兼容模块在伪装，不是真 OSS。

** 用户态的混战: Pipewire 的一统江湖

用户态音频服务器经历了三个时代:

*** 第一代: 直接访问 ALSA (1998-2004)

应用直接打开 =/dev/snd/pcm*=，问题:

- *无法多程序同时播放* (硬件只能被一个进程独占)
- *需要手动配置 dmix 插件* (软件混音)
- *权限管理混乱* (谁能访问声卡?)

*** 第二代: PulseAudio 时代 (2004-2020)

*PulseAudio* (2004, Lennart Poettering 开发) 引入了:

- *网络透明*: 音频可以在网络上传输 (通过 TCP/RTP)
- *Per-application 音量控制*
- *自动设备切换* (插入耳机自动切换)
- *重采样和格式转换*

但 PulseAudio 有严重问题:

- *高延迟* (默认 ~50ms，专业音频不可接受)
- *不支持 JACK* (专业音频软件的标准)
- *稳定性差* (早期版本经常崩溃，"PulseAudio 又挂了" 是 meme)

*** 第三代: JACK 的专业音频生态 (2001-2020)

*JACK (JACK Audio Connection Kit)* 专为低延迟设计:

- *<5ms 延迟* (实时音频处理)
- *灵活的路由图* (应用之间可以任意连接)
- *Sample-accurate 同步* (用于多轨录音)

但问题:

- *普通桌面用户不需要* (配置复杂)
- *与 PulseAudio 冲突* (两者抢占设备)

*** 第四代: Pipewire 的大一统 (2017-现在)

*Pipewire* (2017, Red Hat/Wim Taymans 开发) 是终极解决方案:

- *兼容所有协议*: PulseAudio, JACK, ALSA 应用都能用
- *低延迟*: 默认 ~10ms，可配置到 <1ms (quantum = 32 samples @ 48kHz)
- *视频支持*: 不只是音频，还能处理摄像头 (替代 V4L2)
- *Wayland 集成*: 支持屏幕录制和应用隔离 (通过 xdg-desktop-portal)

关键里程碑:

- *2020 年 10 月*: Fedora 33 首个默认使用 Pipewire
- *2021 年 4 月*: Ubuntu 21.04 默认 Pipewire
- *2022 年 2 月*: Arch Linux 推荐 Pipewire
- *2023 年*: 所有主流发行版 (Debian 12, openSUSE Tumbleweed, Gentoo) 都默认或推荐 Pipewire

会话管理器方面，简陋的 =pipewire-media-session= 也已经被更现代的 =wireplumber= 淘汰 (见后文)。

*所以，有必要重提音频子系统了，重振音频荣光，我辈义不容辞！*

#+begin_quote
*注意*: 用户态音频系统的配置因发行版 / 桌面环境而异，请谨慎甄别。本文以 Pipewire + WirePlumber 为主，偶尔提及 PulseAudio 作为对比。
#+end_quote

* 音频栈的层级结构: 从硬件到应用

在现代 Linux 里，音频从硬件到应用需要经过如下层级:

** 1. 硬件驱动层 (Kernel Space)

- *麦克风 / 扬声器*: 物理声卡硬件
- *ALSA 驱动模块*: 例如 =snd_hda_intel= (Intel HD Audio), =snd_usb_audio= (USB 声卡)
- *驱动注册*: 通过 ALSA kernel API 向内核注册 PCM 设备
- *设备节点*: 暴露为 =/dev/snd/pcmC*D*[p|c]= (p = playback, c = capture)

示例:

#+begin_src sh
$ ls /dev/snd/
controlC0  pcmC0D0c  pcmC0D0p  pcmC0D1p  timer

# C0 = Card 0, D0 = Device 0, p = playback, c = capture
#+end_src

** 2. ALSA 核心层 (Kernel Space)

- *管理硬件抽象*: PCM (音频流), Control (音量 / 开关), MIDI, Timer
- *实现系统调用*: =open()=, =read()=, =write()=, =ioctl()=, =mmap()=
- *用户态接口*: 通过 =libasound.so= 被访问
- *插件系统*: 支持 dmix (混音), dsnoop (多路录音), rate (重采样)

这一层依旧在内核，但提供了标准的 *字符设备接口*。

** 3. ALSA 用户态库 (User Space)

- *libasound.so*: 所有音频程序的基础库
- *打开设备*: =snd_pcm_open()= → =open("/dev/snd/pcmC0D0p")=
- *配置参数*: =snd_pcm_hw_params_*()= → =ioctl(SNDRV_PCM_IOCTL_HW_PARAMS)=
- *读写音频*: =snd_pcm_readi()= / =snd_pcm_writei()= → =read()= / =write()=

这是 Pipewire, PulseAudio, JACK 等所有音频守护进程的 *入口*。

** 4. Pipewire 层 (User Space Daemon)

- *系统级音频 / 视频守护进程*
- *虚拟设备*: Pipewire 会虚拟出 "设备节点"，让应用通过 PulseAudio 或 JACK 协议连接
- *两个进程*:
  - =pipewire=: 主守护进程，处理音频 / 视频图 (graph) 和数据流
  - =wireplumber=: 策略管理器 (session manager)，负责路由规则、权限控制、设备热插拔

** 5. 兼容层 (Optional)

为了让老程序无缝运行，Pipewire 提供了多种兼容层:

- *PulseAudio 兼容*: =pipewire-pulse= (替换 =pulseaudio= daemon)
  - 应用通过 =libpulse.so= 连接
  - 暴露 PulseAudio 的 D-Bus 接口和 Unix socket (=/run/user/1000/pulse/native=)
- *JACK 兼容*: =pipewire-jack= 或通过 =libjack.so= 替换
  - JACK 应用 (Ardour, Carla, qjackctl) 直接连接 Pipewire
- *ALSA 插件*: =libasound_module_pcm_pipewire.so=
  - 让直接访问 ALSA 的应用重定向到 Pipewire
  - 配置文件: =/etc/alsa/conf.d/99-pipewire-default.conf=

** 6. 应用层

现代应用的连接方式:

| 应用类型               | 连接方式                     | 示例                              |
|----------------------+----------------------------+---------------------------------|
| *桌面音频播放器*       | PulseAudio API              | mpv, VLC, Firefox, Chrome       |
| *专业音频制作*         | JACK API                    | Ardour, Reaper, Carla           |
| *游戏引擎*             | SDL2 / OpenAL               | Steam 游戏, Godot               |
| *多媒体框架*           | GStreamer / FFmpeg          | GNOME Videos, OBS Studio        |
| *Wayland 原生*         | xdg-desktop-portal          | Firefox (屏幕共享), Chrome      |
| *虚拟化 / 模拟器*      | 直接访问 Pipewire           | QEMU, VirtualBox                |
| *特效处理*             | Pipewire 原生 API           | EasyEffects, Helvum             |

*** Portal 机制 (Wayland 时代)

在 Wayland 下，应用不能直接访问硬件 (沙箱隔离)，需要通过 *xdg-desktop-portal* 请求权限:

#+begin_example
应用 → xdg-desktop-portal → Pipewire → ALSA → 硬件
#+end_example

例如 Chrome 的麦克风访问:

1. 网页请求麦克风 (=navigator.mediaDevices.getUserMedia()=)
2. Chrome 通过 D-Bus 调用 =org.freedesktop.portal.Desktop= 接口
3. Portal 弹出权限请求对话框 (由桌面环境提供)
4. 用户同意后，Portal 从 Pipewire 创建音频流
5. Chrome 通过 =pipewire-pulse= 接收音频

这比 X11 时代安全得多 (X11 允许应用任意访问设备)。

* PCM: 数字音频的本质

** 什么是 PCM？

*PCM (Pulse-Code Modulation)* 是音频的 *数字化表示*，不压缩，不编码，只是原始波形的数值序列。

物理过程:

1. *声波* (空气压力) → *麦克风* (机械振动) → *电压信号* (模拟)
2. *ADC (Analog-to-Digital Converter)* → *PCM 数字序列*

#+begin_example
声波:  [连续波形]
ADC:   每隔 1/48000 秒采样一次
PCM:   [-127, 305, 1024, 512, -200, ...]  (S16_LE 格式)
#+end_example

MP3 / AAC / Opus / FLAC 都是在 PCM 基础上 *压缩编码* 的结果。

** PCM 的关键参数

*** 1. 采样率 (Sample Rate)

*定义*: 每秒采样多少次 (Hz)，决定 *时间分辨率*。

根据 *奈奎斯特定理* (Nyquist Theorem):

#+begin_quote
采样率必须 ≥ 2 × 最高频率，才能完整重建信号。
#+end_quote

人耳听力范围: 20 Hz ~ 20 kHz，所以理论上 40 kHz 就够了。

| 采样率       | 用途                  | 奈奎斯特频率 |
|------------+----------------------+------------|
| 8000 Hz    | 电话语音 (VoIP)       | 4 kHz      |
| 16000 Hz   | 宽带语音 (VoLTE)      | 8 kHz      |
| 44100 Hz   | CD 音质               | 22.05 kHz  |
| 48000 Hz   | 专业音频 / 视频标准   | 24 kHz     |
| 96000 Hz   | 录音室级 (Hi-Res)     | 48 kHz     |
| 192000 Hz  | 超高保真 (存疑)       | 96 kHz     |

*为什么 48 kHz 而不是 44.1 kHz？*

- 44.1 kHz 是 CD 时代的历史遗留 (由视频标准推导，详见 [[https://en.wikipedia.org/wiki/44,100_Hz][Wikipedia]])
- 48 kHz 是专业音频和视频的标准 (SMPTE, EBU)
- 现代系统 (Pipewire, DAW) 默认 48 kHz

*** 2. 位深 (Bit Depth)

*定义*: 每个采样点的 *数值精度*，决定 *动态范围*。

| 位深       | 数值范围            | 动态范围        | 用途              |
|----------+--------------------+----------------+------------------|
| 8-bit    | 0 ~ 255            | 48 dB          | 老游戏音效        |
| 16-bit   | -32768 ~ 32767     | 96 dB          | CD, 蓝牙耳机      |
| 24-bit   | -8388608 ~ 8388607 | 144 dB         | 专业录音          |
| 32-bit   | ±3.4 × 10³⁸        | 无限 (理论)    | 内部处理 (浮点)   |

*动态范围* 公式: $\text{dB} = 20 \log_{10}(2^n) \approx 6n$ dB。

- 16-bit: 96 dB (约 CD 音质)
- 24-bit: 144 dB (超过人耳极限 ~120 dB)

*为什么 32-bit float？*

在音频处理中 (例如混音、特效)，*浮点数* 可以避免 *削波* (clipping):

#+begin_src c
// 整数会溢出
int16_t a = 30000, b = 30000;
int16_t sum = a + b;  // 溢出！sum = -5536 (截断)

// 浮点数不会
float a = 0.9, b = 0.9;
float sum = a + b;  // 1.8 (超过 [0,1] 范围，但不溢出)
#+end_src

所以现代 DAW (数字音频工作站) 内部都用 *32-bit float* (=F32_LE=)。

*** 3. 声道数 (Channels)

- *Mono* (1): 单声道 (电话, 播客)
- *Stereo* (2): 立体声 (L, R)
- *2.1*: 立体声 + 低音炮 (LFE)
- *5.1*: 环绕声 (L, R, C, LFE, SL, SR)
- *7.1*: 7.1 环绕 (增加 BL, BR)

*** 4. 采样格式 (Sample Format)

ALSA 支持多种格式，常见的:

| 格式       | 描述                      | 字节数 / 样本 | 范围                  |
|----------+---------------------------+-------------+----------------------|
| =S16_LE=   | 有符号 16-bit 小端        | 2           | -32768 ~ 32767       |
| =S24_3LE=  | 有符号 24-bit (3 字节)    | 3           | -8388608 ~ 8388607   |
| =S24_LE=   | 有符号 24-bit (4 字节对齐)| 4           | 同上 (最高字节填充)   |
| =S32_LE=   | 有符号 32-bit 小端        | 4           | ±2³¹                 |
| =F32_LE=   | 32-bit 浮点 (IEEE 754)    | 4           | ±1.0 (归一化)        |

*注意*: =S24_3LE= 和 =S24_LE= 的区别:

- =S24_3LE=: 每个样本占 *3 字节*，紧密打包
- =S24_LE=: 每个样本占 *4 字节*，最高字节填 0 (对齐到 32-bit)

硬件通常只支持对齐格式 (=S24_LE=)，因为 CPU 访问未对齐地址性能差。

*** 5. 比特率 (Bitrate)

公式:

#+begin_example
比特率 (bps) = 采样率 × 位深 × 声道数
#+end_example

示例:

- CD 音质 (44.1 kHz, 16-bit, Stereo):
  $44100 \times 16 \times 2 = 1,411,200$ bps = *1.4 Mbps*

- 专业音频 (48 kHz, 24-bit, Stereo):
  $48000 \times 24 \times 2 = 2,304,000$ bps = *2.3 Mbps*

- 5.1 环绕声 (48 kHz, 24-bit, 6 channels):
  $48000 \times 24 \times 6 = 6,912,000$ bps = *6.9 Mbps*

这就是为什么 PCM 不用于网络传输 (太大！)，需要压缩为 Opus (~64 kbps) 或 MP3 (~128 kbps)。

*** 6. 端序 (Endianness)

- *LE (Little-Endian)*: 小端序，低字节在前 (x86, ARM 默认)
- *BE (Big-Endian)*: 大端序，高字节在前 (网络字节序)

示例: 16-bit 值 =0x1234=

#+begin_example
LE: 内存 [34 12]
BE: 内存 [12 34]
#+end_example

在 x86 / ARM 上，始终用 =_LE= 格式以避免字节序转换开销。

** PCM 设备接口: =/dev/snd/pcmC*D*[p|c]=

ALSA 为每个硬件设备创建设备节点:

#+begin_example
/dev/snd/pcmC0D0p  → Card 0, Device 0, Playback (扬声器)
/dev/snd/pcmC0D0c  → Card 0, Device 0, Capture (麦克风)
/dev/snd/pcmC1D0p  → Card 1, Device 0, Playback (USB 声卡)
#+end_example

查看当前设备:

#+begin_src sh
$ cat /proc/asound/cards
 0 [PCH            ]: HDA-Intel - HDA Intel PCH
                      HDA Intel PCH at 0xf7e10000 irq 135
 1 [U0x46d0x825    ]: USB-Audio - USB Device 0x46d:0x825
                      USB Device 0x46d:0x825 at usb-0000:00:14.0-3, full speed
#+end_src

* ALSA 的系统调用接口

ALSA 设备是 *字符设备*，支持标准的 POSIX 系统调用。

** 核心系统调用

| 操作        | 作用                                      | 典型参数                       |
|----------+------------------------------------------+------------------------------|
| =open()=    | 打开 PCM 设备，分配缓冲区                 | =O_RDONLY= / =O_WRONLY= / =O_RDWR= |
| =ioctl()=   | 配置硬件参数 (采样率, 格式, 缓冲区大小)   | =SNDRV_PCM_IOCTL_*=            |
| =write()=   | 写入 PCM 数据 (播放)                      | 用户态缓冲区 → 内核环形缓冲区   |
| =read()=    | 读取 PCM 数据 (录音)                      | 内核环形缓冲区 → 用户态缓冲区   |
| =poll()=    | 监视可读 / 可写状态 (非阻塞 I/O)          | =POLLIN= / =POLLOUT=           |
| =mmap()=    | 映射 PCM 缓冲区到用户空间 (零拷贝)        | =PROT_READ= / =PROT_WRITE=     |
| =close()=   | 停止 DMA，释放资源                       | -                            |

** 典型流程

#+begin_src c
// 1. 打开设备
int fd = open("/dev/snd/pcmC0D0p", O_WRONLY);

// 2. 配置硬件参数 (通过 ioctl)
struct snd_pcm_hw_params params;
ioctl(fd, SNDRV_PCM_IOCTL_HW_PARAMS, &params);
// 设置: 采样率 48000, 格式 S16_LE, 2 声道

// 3. 准备播放
ioctl(fd, SNDRV_PCM_IOCTL_PREPARE);

// 4. 写入音频数据
int16_t buffer[1024];  // 512 帧 × 2 声道
write(fd, buffer, sizeof(buffer));

// 5. 等待播放完成
ioctl(fd, SNDRV_PCM_IOCTL_DRAIN);

// 6. 关闭设备
close(fd);
#+end_src

** mmap 零拷贝模式

传统 =write()= 需要从用户空间拷贝数据到内核缓冲区，性能开销大。=mmap()= 允许 *直接写入内核缓冲区*:

#+begin_src c
// 映射 PCM 缓冲区
void *buf = mmap(NULL, size, PROT_WRITE, MAP_SHARED, fd, 0);

// 直接写入
int16_t *samples = (int16_t *)buf;
for (int i = 0; i < 1024; i++) {
    samples[i] = ...; // 生成音频
}

// 通知内核数据已写入
ioctl(fd, SNDRV_PCM_IOCTL_SYNC_PTR);
#+end_src

低延迟音频 (如 JACK) 必须用 mmap 模式。

* ALSA 用户态库: libasound.so

虽然可以直接用系统调用，但太底层了。=libasound.so= 提供了高层 C API。

** 核心 API

*** 打开 / 关闭

#+begin_src c
#include <alsa/asoundlib.h>

snd_pcm_t *pcm;
int err = snd_pcm_open(&pcm, "default", SND_PCM_STREAM_PLAYBACK, 0);
if (err < 0) {
    fprintf(stderr, "无法打开设备: %s\n", snd_strerror(err));
}

// ...

snd_pcm_close(pcm);
#+end_src

*** 硬件参数配置

#+begin_src c
snd_pcm_hw_params_t *params;
snd_pcm_hw_params_alloca(&params);
snd_pcm_hw_params_any(pcm, params);

// 设置访问模式 (交错 interleaved)
snd_pcm_hw_params_set_access(pcm, params, SND_PCM_ACCESS_RW_INTERLEAVED);

// 设置格式
snd_pcm_hw_params_set_format(pcm, params, SND_PCM_FORMAT_S16_LE);

// 设置声道数
snd_pcm_hw_params_set_channels(pcm, params, 2);

// 设置采样率
unsigned int rate = 48000;
snd_pcm_hw_params_set_rate_near(pcm, params, &rate, 0);

// 应用配置
snd_pcm_hw_params(pcm, params);
#+end_src

*** 软件参数配置

#+begin_src c
snd_pcm_sw_params_t *swparams;
snd_pcm_sw_params_alloca(&swparams);
snd_pcm_sw_params_current(pcm, swparams);

// 设置启动阈值 (缓冲区填充多少才开始播放)
snd_pcm_sw_params_set_start_threshold(pcm, swparams, buffer_size);

// 设置可用最小值 (poll 唤醒条件)
snd_pcm_sw_params_set_avail_min(pcm, swparams, period_size);

snd_pcm_sw_params(pcm, swparams);
#+end_src

*** I/O 操作

#+begin_src c
// 交错模式 (Interleaved): LRLRLR...
int16_t buffer[1024];  // 512 帧 × 2 声道
snd_pcm_sframes_t frames = snd_pcm_writei(pcm, buffer, 512);

// 非交错模式 (Non-interleaved): LLL... RRR...
int16_t *channels[2] = {left_buf, right_buf};
frames = snd_pcm_writen(pcm, (void **)channels, 512);
#+end_src

*** 状态控制

#+begin_src c
snd_pcm_prepare(pcm);  // 重置到初始状态
snd_pcm_start(pcm);    // 开始播放
snd_pcm_drain(pcm);    // 等待缓冲区播放完
snd_pcm_drop(pcm);     // 立即停止并清空缓冲区
snd_pcm_recover(pcm, err, 0);  // 从 XRUN 恢复
#+end_src

** XRUN: 音频的梦魇

*XRUN* 是音频处理的最大敌人:

- *Underrun* (播放): 应用没能及时提供数据，缓冲区空了 → *卡顿*
- *Overrun* (录音): 应用没能及时读取数据，缓冲区满了 → *丢帧*

检测和恢复:

#+begin_src c
snd_pcm_sframes_t frames = snd_pcm_writei(pcm, buffer, 512);
if (frames == -EPIPE) {
    fprintf(stderr, "Underrun! 恢复中...\n");
    snd_pcm_recover(pcm, -EPIPE, 1);  // silent = 1 (不打印错误)
}
#+end_src

** ALSA 插件系统

ALSA 不只是硬件访问，还有强大的 *插件链*:

#+begin_example
应用 → dmix (混音) → rate (重采样) → hw (硬件)
#+end_example

配置文件: =/etc/alsa/conf.d/= 或 =~/.asoundrc=

示例: 强制 48 kHz 输出

#+begin_src conf
pcm.!default {
    type plug
    slave.pcm "hw:0,0"
    slave.rate 48000
}
#+end_src

常见插件:

- =hw=: 直接访问硬件 (独占)
- =plughw=: 自动格式转换
- =dmix=: 软件混音 (多应用同时播放)
- =dsnoop=: 多应用同时录音
- =pulse=: 重定向到 PulseAudio
- =pipewire=: 重定向到 Pipewire

* Pipewire: 现代音频的中枢

** 架构设计

Pipewire 的核心是一个 *有向图* (Directed Graph):

- *节点 (Node)*: 音频源 / 目的地 (应用, 设备, 特效)
- *端口 (Port)*: 节点的输入 / 输出接口
- *链接 (Link)*: 连接两个端口的数据流

#+begin_example
[麦克风节点]           [浏览器节点]
   (输出端口) ------→ (输入端口)
                 ↓
            [扬声器节点]
              (输入端口)
#+end_example

** SPA (Simple Plugin API)

Pipewire 的底层是 *SPA*，提供:

- *媒体对象模型*: Buffer, Format, Param
- *插件接口*: Node, Device, Monitor
- *类型系统*: 强类型的属性描述

SPA 的设计目标是 *零依赖*，所有对象都是 C 结构体，没有 GLib / Qt 依赖。

** 节点类型

Pipewire 中的节点有两大类:

*** 1. 设备节点 (Device Node)

由 Pipewire 直接管理的硬件设备:

#+begin_example
alsa_output.pci-0000_00_1f.3.analog-stereo
  ├─ Ports:
  │   ├─ playback_FL (Front Left)
  │   ├─ playback_FR (Front Right)
  │   └─ monitor_FL, monitor_FR (回环监听)
  └─ media.class: Audio/Sink
#+end_example

*命名规则*: =<backend>_<direction>.<device-id>.<profile>=

- =backend=: =alsa=, =bluez5=, =v4l2= (摄像头)
- =direction=: =output= (播放), =input= (录音)
- =device-id=: PCI 地址或 USB 序列号
- =profile=: =analog-stereo=, =a2dp-sink= (蓝牙)

*** 2. 流节点 (Stream Node)

应用创建的虚拟音频流:

#+begin_example
Firefox
  ├─ Ports:
  │   └─ output_FL, output_FR
  └─ media.class: Stream/Output/Audio
#+end_example

** 端口类型

每个节点有多个端口，类型:

- =playback=: 硬件输出设备 (扬声器)
- =capture=: 硬件输入设备 (麦克风)
- =input=: 应用接收音频的端口
- =output=: 应用发送音频的端口
- =monitor=: 从播放设备回环出来的副本 (用于录屏软件)

*关键概念*: =monitor= 端口

假设你在播放音乐，同时想用 OBS 录制桌面音频:

#+begin_example
[音乐播放器] → (扬声器的 input 端口) → 物理扬声器
                       ↓
                (monitor 端口) → [OBS 录制]
#+end_example

OBS 连接到扬声器的 =monitor= 端口，就能捕获 "正在播放的声音"。

** 查看 Pipewire 图

*** 命令行工具

#+begin_src sh
# 列出所有节点
$ pw-cli ls Node

# 查看节点详情
$ pw-cli info <node-id>

# 导出完整图 (JSON)
$ pw-dump > graph.json

# 实时监控
$ pw-top
#+end_src

*** 图形化工具

- *Helvum*: Rust 写的图形化连接管理器 (类似 qjackctl)
- *qpwgraph*: Qt 版本
- *Carla*: 专业音频插件宿主

#+begin_src sh
# Gentoo 安装
$ emerge --ask media-sound/helvum

# 运行
$ helvum
#+end_src

** 链接操作

手动建立链接:

#+begin_src sh
# 列出所有端口
$ pw-link --links

# 连接麦克风到扬声器 (回声测试)
$ pw-link "alsa_input.pci-0000_00_1f.3.analog-stereo:capture_FL" \
          "alsa_output.pci-0000_00_1f.3.analog-stereo:playback_FL"

# 断开
$ pw-link --disconnect <link-id>
#+end_srC

** Pipewire 配置

配置文件位置 (优先级从高到低):

1. =~/.config/pipewire/pipewire.conf= (用户)
2. =/etc/pipewire/pipewire.conf= (系统)
3. =/usr/share/pipewire/pipewire.conf= (默认)

关键配置项:

#+begin_src conf
context.properties = {
    default.clock.rate = 48000         # 默认采样率
    default.clock.allowed-rates = [ 44100 48000 96000 ]
    default.clock.quantum = 1024       # 缓冲区大小 (帧数)
    default.clock.min-quantum = 32     # 最小延迟模式
    default.clock.max-quantum = 8192   # 高延迟模式
}
#+end_src

*Quantum 的含义*:

- Quantum = 每次处理的 *帧数*
- 延迟 = Quantum / 采样率
- 示例: Quantum = 1024, 采样率 = 48000 Hz
  → 延迟 = 1024 / 48000 = *21.3 ms*

低延迟配置 (JACK 风格):

#+begin_src conf
default.clock.quantum = 64        # 1.3 ms @ 48 kHz
default.clock.min-quantum = 32    # 0.67 ms
#+end_src

但低延迟会增加 CPU 负载和 XRUN 风险！

* WirePlumber: Pipewire 的大脑

Pipewire 只是一个 *数据流引擎*，不知道 "谁该连谁, 何时切换, 谁优先"。*WirePlumber* 负责 *策略管理*。

** 历史: pipewire-media-session 的失败

早期 Pipewire 使用 =pipewire-media-session=，它只是个 *毛坯房*:

- 无 D-Bus 接口 (无法被桌面环境控制)
- 无脚本系统 (规则硬编码)
- 无配置文件 (所有设置在代码里)

2021 年，GNOME / KDE / Red Hat 工程师忍无可忍，开始设计 *WirePlumber*:

- *Lua 脚本引擎*: 所有规则用 Lua 编写
- *模块化架构*: 功能分散到独立模块
- *D-Bus 集成*: 与桌面环境无缝协作

*关键里程碑*:

- *2021 年 7 月*: WirePlumber 0.4 发布，支持 Lua 脚本
- *2021 年 9 月*: Pipewire 官方推荐 WirePlumber
- *2022 年*: =pipewire-media-session= 停止维护
- *2023 年*: 所有发行版默认 WirePlumber

** WirePlumber 的职责

1. *设备热插拔*: 插入 USB 声卡 / 蓝牙耳机 → 自动切换
2. *默认设备管理*: 哪个是默认扬声器？哪个是默认麦克风？
3. *音频路由*: 应用 A 连接到设备 B
4. *权限控制*: Flatpak 应用能访问哪些设备？
5. *配置持久化*: 音量设置, 设备偏好

** WirePlumber 模块

WirePlumber 本身是个 *空壳*，所有功能都在模块里:

| 模块                           | 作用                         |
|------------------------------+------------------------------|
| =libwireplumber-module-default-nodes= | 管理默认设备             |
| =libwireplumber-module-default-profile= | 管理声卡 Profile        |
| =libwireplumber-module-metadata= | 存储元数据 (音量, 路由)      |
| =libwireplumber-module-mixer-api= | 音量控制                   |
| =libwireplumber-module-si-audio-adapter= | 自动连接音频流         |
| =libwireplumber-module-si-audio-endpoint= | 虚拟端点             |

模块配置: =/etc/wireplumber/wireplumber.conf=

#+begin_src lua
load_module("libwireplumber-module-default-nodes")
#+end_src

** Lua 脚本规则

WirePlumber 用 *Lua 脚本* 定义路由规则，位于 =/etc/wireplumber/main.lua.d/= 或 =~/.config/wireplumber/main.lua.d/=。

*** 示例 1: 强制 Firefox 使用 USB 声卡

#+begin_src lua
rule = {
  matches = {
    {
      { "application.name", "equals", "Firefox" },
    },
  },
  apply_properties = {
    ["node.target"] = "alsa_output.usb-046d_0825-00.analog-stereo",
  },
}

table.insert(alsa_monitor.rules, rule)
#+end_src

*** 示例 2: 禁用某个设备

#+begin_src lua
rule = {
  matches = {
    {
      { "device.name", "equals", "alsa_card.pci-0000_01_00.1" },  -- HDMI 声卡
    },
  },
  apply_properties = {
    ["device.disabled"] = true,
  },
}
#+end_src

** 配置文件结构

WirePlumber 的配置分散在多个目录:

#+begin_example
/etc/wireplumber/
├── main.lua.d/               # 主配置脚本
│   ├── 50-default-access-config.lua
│   ├── 50-alsa-config.lua
│   └── 99-custom-rules.lua   # 你的自定义规则
├── bluetooth.lua.d/          # 蓝牙配置
├── policy.lua.d/             # 策略脚本
└── wireplumber.conf          # 主配置文件 (加载模块)
#+end_example

用户级配置 (覆盖系统配置):

#+begin_example
~/.config/wireplumber/
└── main.lua.d/
    └── 99-my-rules.lua
#+end_example

** 调试 WirePlumber

查看 WirePlumber 日志:

#+begin_src sh
$ journalctl --user -u wireplumber.service -f
#+end_src

重启 WirePlumber:

#+begin_src sh
$ systemctl --user restart wireplumber.service
#+end_src

检查配置语法:

#+begin_src sh
$ wireplumber --check-config
#+end_src

* 实战: 常见配置和故障排查

** 场景 1: 设置默认音频设备

*** 图形化方式

- GNOME: *设置 → 声音 → 输出 / 输入*
- KDE: *系统设置 → 多媒体 → 音频*
- Pavucontrol (通用): =$ pavucontrol=

*** 命令行方式

#+begin_src sh
# 列出所有 Sink (输出设备)
$ pactl list short sinks
0  alsa_output.pci-0000_00_1f.3.analog-stereo  module-alsa-card.c  s16le 2ch 48000Hz
1  alsa_output.usb-046d_0825-00.analog-stereo  module-alsa-card.c  s16le 2ch 48000Hz

# 设置默认
$ pactl set-default-sink alsa_output.usb-046d_0825-00.analog-stereo

# 列出所有 Source (输入设备)
$ pactl list short sources

# 设置默认麦克风
$ pactl set-default-source alsa_input.usb-046d_0825-00.mono-fallback
#+end_src

** 场景 2: 强制应用使用特定设备

*** 使用 =pw-link=

#+begin_src sh
# 先找到应用的节点 ID
$ pw-cli ls Node | grep -i firefox

# 手动连接
$ pw-link Firefox:output_FL alsa_output.usb:playback_FL
#+end_src

*** 使用 WirePlumber 规则

见上文 Lua 脚本示例。

** 场景 3: 录制桌面音频 (回环)

使用扬声器的 =monitor= 端口:

#+begin_src sh
# 找到 monitor 源
$ pactl list short sources | grep monitor
2  alsa_output.pci-0000_00_1f.3.analog-stereo.monitor

# 用 FFmpeg 录制
$ ffmpeg -f pulse -i alsa_output.pci-0000_00_1f.3.analog-stereo.monitor \
         -ac 2 -ar 48000 output.mp3
#+end_src

** 场景 4: 蓝牙耳机延迟高

蓝牙音频有两种协议:

- *A2DP* (Advanced Audio Distribution Profile): 高音质，但延迟 ~100-200 ms
- *HSP/HFP* (Headset/Hands-Free Profile): 低延迟 (~30 ms)，但音质差

切换协议:

#+begin_src sh
# 查看当前 Profile
$ pactl list cards | grep -A 20 "bluez"

# 切换到 HSP/HFP (低延迟)
$ pactl set-card-profile bluez_card.XX_XX_XX_XX_XX_XX headset-head-unit

# 切换回 A2DP (高音质)
$ pactl set-card-profile bluez_card.XX_XX_XX_XX_XX_XX a2dp-sink
#+end_src

*根本解决*: 使用低延迟蓝牙编解码器 (aptX, LDAC)，需要硬件支持。

** 场景 5: 无声音 / 设备未识别

*** 检查 ALSA

#+begin_src sh
# 检查声卡是否被识别
$ cat /proc/asound/cards

# 测试硬件
$ speaker-test -D hw:0 -c 2
#+end_src

*** 检查 Pipewire

#+begin_src sh
# Pipewire 是否运行？
$ systemctl --user status pipewire.service

# WirePlumber 是否运行？
$ systemctl --user status wireplumber.service

# 检查节点
$ pw-cli ls Node
#+end_src

*** 检查权限

用户必须在 =audio= 组:

#+begin_src sh
$ groups $USER
$ sudo usermod -aG audio $USER
#+end_src

然后 *重新登录*。

** 场景 6: 音频卡顿 / XRUN

原因:

- Quantum 太小 (CPU 跟不上)
- CPU 频率被限制 (节能模式)
- 其他进程抢占 CPU

解决:

#+begin_src sh
# 增大 Quantum (减少 CPU 负载)
$ pw-metadata -n settings 0 clock.force-quantum 2048

# 检查 CPU 频率策略
$ cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# 切换到 performance 模式
$ sudo cpupower frequency-set -g performance
#+end_src

** 场景 7: Firefox / Chrome 无声音

检查 Portal 权限:

#+begin_src sh
# Firefox 使用 pipewire-pulse
$ pactl list sink-inputs | grep -i firefox

# Chrome 使用 Pipewire Portal
$ pw-cli ls Node | grep -i chrome
#+end_src

如果 Chrome 显示 "麦克风被阻止":

1. 检查 =~/.config/pulse/client.conf= 是否重定向到 Pipewire
2. 重启浏览器
3. 在 =chrome://settings/content/microphone= 允许权限

* 性能优化与低延迟配置

** 延迟的来源

音频延迟 (latency) 由多个因素叠加:

| 环节                   | 延迟          | 备注                      |
|----------------------+-------------+--------------------------|
| ADC (模数转换)         | ~0.1 ms     | 硬件延迟                  |
| ALSA 缓冲区            | 2-10 ms     | 取决于 =buffer_size=        |
| Pipewire Quantum       | 1-20 ms     | 取决于配置                |
| 应用缓冲区             | 10-50 ms    | 应用自己的环形缓冲区      |
| 网络传输 (如蓝牙)      | 50-200 ms   | A2DP 延迟                |
| DAC (数模转换)         | ~0.1 ms     | 硬件延迟                  |

总延迟 = 所有环节之和。

** 低延迟配置 (专业音频)

*** 1. 降低 Pipewire Quantum

#+begin_src conf
# ~/.config/pipewire/pipewire.conf
context.properties = {
    default.clock.rate = 48000
    default.clock.quantum = 64        # 1.3 ms @ 48 kHz
    default.clock.min-quantum = 32    # 0.67 ms
}
#+end_src

*** 2. 使用实时调度

启用 =rtkit= (Real-Time Kit):

#+begin_src sh
$ systemctl --user status rtkit-daemon.service
#+end_src

配置 Pipewire 使用实时优先级:

#+begin_src conf
context.modules = [
    {
        name = libpipewire-module-rt
        args = {
            nice.level = -11
            rt.prio = 20
        }
    }
]
#+end_src

*** 3. CPU 频率锁定

#+begin_src sh
$ sudo cpupower frequency-set -g performance
$ sudo cpupower frequency-set -d 3.5GHz  # 最低 3.5 GHz
#+end_src

*** 4. 禁用节能功能

#+begin_src sh
# 禁用 C-states (CPU 深度睡眠)
$ sudo cpupower idle-set -D 0

# 禁用 Turbo Boost (避免频率抖动)
$ echo 1 | sudo tee /sys/devices/system/cpu/intel_pstate/no_turbo
#+end_src

** 测量实际延迟

使用 =jack_delay= (需要环回线):

#+begin_src sh
# 物理环回: 扬声器输出 → 麦克风输入
$ jack_delay -O system:playback_1 -I system:capture_1

# 输出: Round-trip latency: 5.2 ms
#+end_src

* 总结: 音频栈的完整路径

#+begin_example
应用 (Firefox)
  ↓ libpulse.so (PulseAudio API)
  ↓ pipewire-pulse (兼容层)
  ↓ Pipewire Core (图引擎)
  ↓ WirePlumber (策略管理)
  ↓ libasound.so (ALSA 用户态库)
  ↓ /dev/snd/pcmC0D0p (设备节点)
  ↓ ALSA 内核驱动 (snd_hda_intel)
  ↓ DMA (直接内存访问)
  ↓ DAC (数模转换)
  ↓ 扬声器 (物理硬件)
#+end_example

** 关键技术点回顾

1. *ALSA* 是内核音频框架，提供 PCM / Control / MIDI 接口
2. *Pipewire* 是用户态音频 / 视频图服务器，兼容 PulseAudio / JACK / ALSA
3. *WirePlumber* 是 Pipewire 的会话管理器，用 Lua 脚本定义路由规则
4. *低延迟* 需要降低 Quantum, 启用实时调度, 锁定 CPU 频率
5. *mmap 零拷贝* 是专业音频的必备技术

** 推荐工具

- *图形化*: Helvum (连接管理), Pavucontrol (音量控制), EasyEffects (特效)
- *命令行*: =pw-cli=, =pw-top=, =pactl=, =speaker-test=
- *开发*: =libasound=, =libpipewire=, =libjack=

** 延伸阅读

- [[https://docs.pipewire.org/][Pipewire 官方文档]]
- [[https://pipewire.pages.freedesktop.org/wireplumber/][WirePlumber 官方文档]]
- [[https://www.alsa-project.org/wiki/Main_Page][ALSA Wiki]]
- [[https://jackaudio.org/][JACK Audio Connection Kit]]

*Linux 音频已经不再是 "一坨屎" 了，现在是时候拥抱 Pipewire 了！*
