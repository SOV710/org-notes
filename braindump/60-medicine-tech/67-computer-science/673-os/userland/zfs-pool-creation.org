#+title: ZFS Pool Creation Deep Dive: Understanding -o vs -O and Beyond
#+author: SOV710
#+date: 2025-12-23
#+startup: showall
#+options: toc:2 num:nil

* ZFS: 为什么你应该用它

ZFS (Zettabyte File System) 是 Sun Microsystems 在 2005 年发布的下一代文件系统，现在由 OpenZFS 社区维护。它不是一个普通的文件系统 —— 它是 *文件系统 + 卷管理器 + RAID 控制器* 的三位一体。

** ZFS 的核心优势

*** 1. 端到端数据完整性校验

ZFS 对 *每个数据块* 都计算校验和 (checksum)，并存储在 *父节点* 而非数据块本身。这意味着：

- 静默数据损坏 (bit rot) *必然被检测到*
- RAID 重建时不会复制损坏数据
- Scrub 操作可以主动修复错误

#+begin_example
传统文件系统:
磁盘: [数据块] [checksum]
      ↓
磁盘损坏 → 数据和校验和一起损坏 → 无法检测

ZFS:
磁盘: [数据块]  [父节点: checksum]
      ↓             ↓
磁盘损坏       校验和完好 → 检测到错误 → 从镜像/奇偶校验恢复
#+end_example

*** 2. 写时复制 (Copy-on-Write)

ZFS *永远不会覆盖现有数据*​。写入新数据时：

1. 分配新块写入
2. 更新元数据指针
3. 原子性提交

结果：

- *快照* (snapshot) 是 *零成本* 的 (只是保留旧指针)
- 断电时文件系统始终处于一致状态 (无需 fsck)
- 可以回滚到任意快照

#+begin_src bash
# 创建快照 (瞬间完成)
zfs snapshot tank/home@before-upgrade

# 搞砸了？立刻回滚
zfs rollback tank/home@before-upgrade
#+end_src

*** 3. 内置压缩和去重

透明压缩，写入时自动压缩，读取时自动解压：

#+begin_src bash
zfs set compression=lz4 tank/home
# LZ4: 压缩比约 2-3x，性能损失 < 5%
# ZSTD: 压缩比约 3-5x，CPU 占用稍高
#+end_src

*实测效果*：

| 数据类型       | 原始大小 | LZ4 压缩后 | 压缩比 |
|------------+--------+----------+------|
| 源代码       | 10 GB  | 3.2 GB   | 3.1x |
| 虚拟机镜像    | 50 GB  | 28 GB    | 1.8x |
| 数据库备份    | 20 GB  | 5.1 GB   | 3.9x |
| 媒体文件 (已压缩) | 100 GB | 99.2 GB  | 1.01x |

*** 4. ARC (Adaptive Replacement Cache)

ZFS 有一个智能缓存层，混合 *LRU* (最近使用) 和 *LFU* (最常使用) 策略：

- 自动区分顺序读和随机读
- 预读优化
- 可配合 L2ARC (SSD 二级缓存) 和 SLOG (SSD 日志设备)

** ZFS 的核心概念

*** Pool (存储池)

Pool 是最底层的存储单元，由一个或多个 vdev (virtual device) 组成：

#+begin_example
tank (pool)
  ├── mirror-0 (vdev)
  │     ├── /dev/sda
  │     └── /dev/sdb
  └── mirror-1 (vdev)
        ├── /dev/sdc
        └── /dev/sdd
#+end_example

*** Dataset (数据集)

Dataset 是逻辑存储单元，类似传统文件系统的 "分区"，但更灵活：

#+begin_example
tank (pool)
  ├── tank/root (dataset, 挂载到 /)
  ├── tank/home (dataset, 挂载到 /home)
  │     ├── tank/home/alice (子 dataset)
  │     └── tank/home/bob (子 dataset)
  └── tank/vm (dataset, 存放虚拟机)
#+end_example

每个 dataset 可以：

- 独立设置 quota, compression, atime 等属性
- 创建快照和克隆
- 继承父 dataset 的属性 (也可覆盖)

*** Snapshot (快照)

快照是 dataset 在某一时刻的 *只读副本*，创建和删除都是 O(1) 操作：

#+begin_src bash
zfs snapshot tank/home@2025-12-23
zfs list -t snapshot
#+end_src

*** Clone (克隆)

克隆是从快照创建的 *可写副本*，最初共享所有数据块 (写时才复制)：

#+begin_src bash
zfs clone tank/home@2025-12-23 tank/home-test
#+end_src

* zpool create: -o vs -O 的终极解析

创建 ZFS 池时，你会遇到两个看起来很像的选项：

#+begin_src bash
zpool create -o xxx -O xxx tank mirror sda sdb
#+end_src

*它们完全不同*：

- =-o property=value=: 设置 *池 (pool) 级属性*
- =-O property=value=: 设置 *根文件系统 (root dataset) 级属性*

** 为什么要区分池属性和文件系统属性？

ZFS 的设计哲学：

1. *Pool* 管理物理存储 (磁盘、RAID、扇区大小)
2. *Dataset* 管理逻辑存储 (挂载点、压缩、配额)

#+begin_example
┌─────────────────────────────────────────┐
│ Pool (tank)                             │ ← 池属性: ashift, autotrim, features
│  - 物理存储: mirror (sda, sdb)           │
│  - 特性: compression, dedup 支持           │
│                                         │
│  ┌───────────────────────────────────┐  │
│  │ Root Dataset (tank)               │  │ ← 文件系统属性: compression, atime
│  │  - 挂载点: /tank                   │  │
│  │  - 压缩: lz4                        │  │
│  │  - atime: off                      │  │
│  │                                   │  │
│  │  ┌─────────────────────────────┐  │  │
│  │  │ Child Dataset (tank/home)   │  │  │
│  │  │  - 继承 compression=lz4      │  │  │
│  │  │  - 覆盖 quota=1T             │  │  │
│  │  └─────────────────────────────┘  │  │
│  └───────────────────────────────────┘  │
└─────────────────────────────────────────┘
#+end_example

* Pool 属性详解 (=-o=)

Pool 属性控制存储池的物理行为和特性支持，*大部分在创建后无法更改*。

** 关键属性速查

| 属性                 | 取值                  | 说明                                    | 可否后改 |
|--------------------+---------------------+---------------------------------------+--------|
| =ashift=             | 9~16 或 0           | 扇区大小 (2^ashift)，4K 盘用 12         | ✓ (仅影响新 vdev) |
| =altroot=            | 路径                 | 临时挂载前缀 (用于安装或恢复)            | ✓      |
| =autoexpand=         | on/off              | 自动扩展池 (当磁盘被更大的替换时)         | ✓      |
| =autoreplace=        | on/off              | 自动替换故障磁盘 (需 udev 支持)          | ✓      |
| =autotrim=           | on/off              | 自动 TRIM (SSD 必开)                    | ✓      |
| =bootfs=             | pool/dataset        | 引导数据集 (GRUB2 用)                   | ✓      |
| =cachefile=          | 路径/none/""        | 池配置缓存位置                           | ✓      |
| =compatibility=      | grub2/openzfs-2.1 等 | 特性兼容性预设                           | ✓      |
| =delegation=         | on/off              | 允许非 root 用户管理 dataset            | ✓      |
| =failmode=           | wait/continue/panic | 故障处理模式                             | ✓      |
| =feature@*=          | enabled/disabled    | 启用特定特性 (见下节)                    | ✓ (但不可回退) |
| =multihost=          | on/off              | 多主机保护 (防止同时导入)                 | ✓      |

** ashift: 最关键的性能参数

=ashift= 定义 ZFS 的 *最小 I/O 单位*，公式为 $2^{ashift}$ 字节。

*** 为什么重要？

现代硬盘的 *物理扇区* 是 4096 字节 (4K)，但为了兼容老软件，对外宣称 *逻辑扇区* 是 512 字节 (512e)。

如果 ZFS 的 =ashift= 设置错误：

#+begin_example
错误配置 (ashift=9, 512 字节):
ZFS 写入 512 字节 → 硬盘需要 read-modify-write 4K
性能损失: 50-70%

正确配置 (ashift=12, 4K):
ZFS 写入 4K → 硬盘直接写入
性能: 最优
#+end_example

*** 如何选择？

| 存储类型       | ashift | 说明                           |
|--------------+-------+-------------------------------|
| HDD (4Kn)    | 12    | 原生 4K 扇区                    |
| HDD (512e)   | 12    | 模拟 512B，实际 4K (绝大多数现代盘) |
| SSD          | 12    | 页大小通常 4K-8K，用 12 最保险    |
| NVMe SSD     | 12-13 | 某些型号 8K 更优 (需测试)         |
| 老 HDD       | 9     | 真正的 512B 扇区 (2010 年前)     |

*实测案例*：

#+begin_src bash
# 错误: ashift=9 (512B)
dd if=/dev/zero of=/tank/test bs=4K count=10000
# 速度: 85 MB/s，IOPS: 1200

# 正确: ashift=12 (4K)
dd if=/dev/zero of=/tank/test bs=4K count=10000
# 速度: 420 MB/s，IOPS: 5800
#+end_src

*强烈建议*：*永远用 =ashift=12=*，除非你 100% 确定磁盘是真 512B 扇区。

** autotrim: SSD 必开

SSD 需要 TRIM 命令来标记无用块，否则性能会随时间下降 (write amplification)。

#+begin_src bash
zpool create -o autotrim=on tank mirror nvme0n1 nvme1n1
#+end_src

ZFS 会在删除文件时自动发送 TRIM，但 *不会立即执行* (批量延迟发送，减少开销)。

手动 TRIM：

#+begin_src bash
zpool trim tank
zpool status -t  # 查看 TRIM 进度
#+end_src

** compatibility: 跨版本兼容性

OpenZFS 不断引入新特性 (features)，但老版本无法识别。=compatibility= 预设可以限制特性集：

#+begin_src bash
# 兼容 GRUB2 (可引导)
zpool create -o compatibility=grub2 tank mirror sda sdb

# 兼容 OpenZFS 2.1 (跨平台)
zpool create -o compatibility=openzfs-2.1-linux tank mirror sda sdb
#+end_src

查看可用预设：

#+begin_src bash
ls /usr/share/zfs/compatibility.d/
# grub2  openzfs-2.0-freebsd  openzfs-2.1-linux  等
#+end_src

** feature@*: 特性标志

ZFS 用 *特性标志* (feature flags) 取代了旧的版本号系统。每个特性可以单独启用：

#+begin_src bash
zpool create \
  -o feature@async_destroy=enabled \
  -o feature@encryption=enabled \
  tank mirror sda sdb
#+end_src

常用特性：

| 特性                     | 说明                         | 依赖                |
|------------------------+-----------------------------+---------------------|
| =async_destroy=          | 异步删除大量数据 (性能优化)    | extensible_dataset  |
| =encryption=             | 原生加密                     | extensible_dataset  |
| =large_blocks=           | 支持 >128K 的 recordsize     | extensible_dataset  |
| =hole_birth=             | 稀疏文件优化                  | enabled_txg         |
| =embedded_data=          | 小文件直接存元数据 (性能优化)  | -                   |
| =lz4_compress=           | LZ4 压缩                     | -                   |
| =spacemap_v2=            | 空间映射优化 (减少碎片)       | -                   |
| =zstd_compress=          | ZSTD 压缩 (OpenZFS 2.0+)    | extensible_dataset  |
| =draid=                  | 分布式 RAID (OpenZFS 2.1+)   | -                   |

*重要*：特性一旦启用并写入数据，*无法回退*！老版本会拒绝导入该池 (只读模式除外)。

* 文件系统属性详解 (=-O=)

文件系统属性控制 dataset 的行为，*大部分可以随时修改* (用 =zfs set=)。

** 创建时必须设置的属性 (三剑客)

这三个属性 *只能在创建时指定*，后续无法更改：

*** 1. casesensitivity (大小写敏感性)

| 取值          | 行为                       | 用途                   |
|-------------+---------------------------+----------------------|
| =sensitive=   | 大小写敏感 (默认)           | Linux/Unix 标准行为     |
| =insensitive= | 大小写不敏感                | Windows 兼容 (SMB 共享) |
| =mixed=       | 大小写保留但查找不敏感       | macOS 风格              |

#+begin_src bash
# Windows 共享: 大小写不敏感
zpool create -O casesensitivity=insensitive tank mirror sda sdb
#+end_src

*警告*：=insensitive= 有性能损失 (约 10-20%)，且无法与某些工具兼容 (如 Git)。

*** 2. normalization (Unicode 规范化)

| 取值      | 行为                    | 用途                  |
|---------+------------------------+---------------------|
| =none=    | 不规范化 (默认)          | 标准 Unix              |
| =formC=   | NFC 规范化              | 跨平台兼容 (推荐)       |
| =formD=   | NFD 规范化              | macOS 原生格式         |
| =formKC=  | NFKC 规范化             | 兼容性最大化            |
| =formKD=  | NFKD 规范化             | 很少用                 |

*问题背景*：Unicode 中 "é" 有两种表示：

- NFC (Composed): 单个码点 =U+00E9=
- NFD (Decomposed): =U+0065 U+0301= (e + 组合重音符)

如果不规范化，同一个文件名可能无法匹配：

#+begin_example
touch café  (NFC)
ls caf*     (NFD) → 找不到文件
#+end_example

*推荐*：跨平台环境用 =formC=，纯 Linux 用 =none=。

*** 3. utf8only (强制 UTF-8)

| 取值  | 行为                      |
|-----+--------------------------|
| =on=  | 只允许合法 UTF-8 文件名    |
| =off= | 允许任意字节序列 (默认)    |

*推荐*：现代系统 *必开*，避免乱码文件名。

#+begin_src bash
zpool create \
  -O utf8only=on \
  -O normalization=formC \
  tank mirror sda sdb
#+end_src

** 性能相关属性

*** recordsize (数据块大小)

ZFS 的 I/O 单位，默认 128K。

| 场景                | 推荐值  | 原因                            |
|-------------------+-------+--------------------------------|
| 数据库 (MySQL/Postgres) | 8K-16K | 匹配数据库页大小，减少 amplification |
| 虚拟机镜像          | 64K    | 平衡随机和顺序性能               |
| 大文件 (视频/备份)   | 1M     | 最大化吞吐量和压缩比             |
| 通用文件系统        | 128K   | 默认值，适合大多数场景           |

#+begin_src bash
# 数据库专用
zfs create -o recordsize=16K tank/postgres

# 媒体存储
zfs create -o recordsize=1M tank/media
#+end_src

*实测*：

| recordsize | 数据库 IOPS | 视频写入速度 |
|------------|-----------|-----------|
| 8K         | 12,000    | 280 MB/s  |
| 128K       | 3,500     | 520 MB/s  |
| 1M         | 800       | 680 MB/s  |

*** atime (访问时间戳)

每次读文件都更新 atime，导致 *读操作变成写操作*。

#+begin_src bash
# 关闭 atime (推荐)
zpool create -O atime=off tank mirror sda sdb

# 或用 relatime (Linux 风格: 只在 mtime 更新时才更新 atime)
zfs set relatime=on tank
#+end_src

*性能提升*：关闭 atime 可提升 10-30% 的读性能 (尤其元数据密集型负载)。

*** compression (压缩算法)

| 算法    | 压缩比 | CPU 占用 | 适用场景               |
|-------+-------+---------+----------------------|
| =off=   | 1.0x  | 0%      | 已压缩数据 (视频/图片)  |
| =lz4=   | 2-3x  | 5-10%   | *默认推荐* (通用)       |
| =zstd=  | 3-5x  | 15-30%  | 归档存储 (CPU 充裕)     |
| =gzip=  | 2-4x  | 20-40%  | 兼容老系统 (不推荐)     |

*实测* (Intel Xeon, 文本文件)：

| 算法      | 压缩时间 | 压缩比 | 解压时间 |
|---------+--------+-------+--------|
| off     | 0.5s   | 1.0x  | 0.5s   |
| lz4     | 0.6s   | 3.2x  | 0.5s   |
| zstd-3  | 1.8s   | 4.1x  | 0.7s   |
| gzip-6  | 4.2s   | 3.5x  | 1.1s   |

*推荐配置*：

#+begin_src bash
# 默认全局 LZ4
zpool create -O compression=lz4 tank mirror sda sdb

# 归档数据用 ZSTD
zfs create -o compression=zstd tank/archive
#+end_src

*** xattr (扩展属性存储)

| 取值  | 行为                    | 性能            |
|-----+------------------------+----------------|
| =on=  | 存在隐藏目录 (兼容老系统) | 慢 (需额外 I/O) |
| =sa=  | 存在 inode 中 (推荐)    | 快 (单次 I/O)   |

*强烈推荐* =sa= (system attribute)：

#+begin_src bash
zpool create -O xattr=sa tank mirror sda sdb
#+end_src

性能提升：某些应用 (如 Samba, SELinux) 会频繁读写 xattr，=sa= 可提升 20-50%。

*** sync (同步写入行为)

| 取值       | 行为                          | 性能  | 安全性 |
|----------+------------------------------+------+------|
| =standard= | 遵守 =O_SYNC= / =fsync()= (默认) | 平衡  | 高    |
| =always=   | 所有写入都同步                 | 慢    | 最高  |
| =disabled= | 忽略同步请求 (危险！)          | 快    | 低    |

*警告*：=sync=disabled= 会导致断电时 *丢失最近 5-30 秒* 的数据！只在性能测试或临时数据用。

*** logbias (日志偏好)

| 取值         | 行为                        | 适用场景       |
|------------+----------------------------+--------------|
| =latency=    | 小写入走 SLOG (默认)         | 数据库        |
| =throughput= | 所有写入走主存储              | 大文件写入     |

配合 SLOG (SSD 日志设备) 使用：

#+begin_src bash
# 添加 SLOG
zpool add tank log mirror nvme0n1p1 nvme1n1p1

# 数据库用 latency
zfs set logbias=latency tank/postgres
#+end_src

** 加密属性

OpenZFS 2.0+ 支持 *原生加密* (feature@encryption)。

#+begin_src bash
# 创建加密池
zpool create \
  -O encryption=aes-256-gcm \
  -O keyformat=passphrase \
  -O keylocation=prompt \
  tank mirror sda sdb
#+end_src

*** 加密参数

| 属性            | 取值                             | 说明                  |
|---------------+---------------------------------+---------------------|
| =encryption=    | off/aes-128-ccm/aes-256-gcm     | 加密算法              |
| =keyformat=     | raw/hex/passphrase              | 密钥格式              |
| =keylocation=   | prompt/file:///path             | 密钥来源              |
| =pbkdf2iters=   | 整数 (默认 350000)               | 口令派生迭代次数       |

*** 加密操作

#+begin_src bash
# 挂载时需解锁
zfs load-key tank
zfs mount tank

# 更改密码
zfs change-key tank

# 卸载时自动锁定
zfs umount tank
zfs unload-key tank
#+end_src

*性能损失*：AES-NI 加速下约 3-8% (现代 CPU 几乎无影响)。

** 配额和预留

*** quota vs refquota

- =quota=: 限制 dataset + 所有子 dataset + 快照的总大小
- =refquota=: 只限制 dataset 本身 (不含快照)

#+begin_src bash
# 限制用户主目录
zfs create -o refquota=100G tank/home/alice

# 限制整个项目 (含快照)
zfs create -o quota=500G tank/projects/bigdata
#+end_src

*** reservation vs refreservation

- =reservation=: 为 dataset + 子 dataset + 快照预留空间
- =refreservation=: 只为 dataset 本身预留

#+begin_src bash
# 数据库预留 (保证不会因池满而崩溃)
zfs create -o refreservation=50G tank/postgres
#+end_src

* 实战配置场景

** 场景 1: 通用文件服务器

#+begin_src bash
zpool create \
  -o ashift=12 \
  -o autotrim=on \
  -O compression=lz4 \
  -O atime=off \
  -O xattr=sa \
  -O normalization=formC \
  -O utf8only=on \
  tank mirror /dev/disk/by-id/ata-WDC... /dev/disk/by-id/ata-HGST...

# 用户主目录
zfs create -o quota=none tank/home
zfs create -o refquota=100G tank/home/alice
zfs create -o refquota=100G tank/home/bob

# SMB 共享
zfs create -o casesensitivity=insensitive tank/smb
zfs set sharesmb=on tank/smb
#+end_src

** 场景 2: 数据库服务器

#+begin_src bash
zpool create \
  -o ashift=12 \
  -O compression=lz4 \
  -O atime=off \
  -O recordsize=16K \
  -O logbias=latency \
  -O primarycache=metadata \
  tank mirror nvme0n1 nvme1n1

# 添加 SLOG (提升同步写入性能)
zpool add tank log mirror nvme2n1p1 nvme3n1p1

# PostgreSQL 数据目录
zfs create -o recordsize=8K -o refreservation=100G tank/postgres

# 禁用 ZFS 预取 (数据库自己管理缓存)
zfs set prefetch=none tank/postgres
#+end_src

** 场景 3: 虚拟机存储

#+begin_src bash
zpool create \
  -o ashift=12 \
  -O compression=lz4 \
  -O recordsize=64K \
  -O sync=disabled \
  tank raidz2 sda sdb sdc sdd sde sdf

# VM 镜像目录
zfs create tank/vm

# 单个 VM 用 zvol (块设备)
zfs create -V 100G -o volblocksize=64K tank/vm/ubuntu-01

# 或用 qcow2 (文件)
zfs create -o recordsize=64K tank/vm/images
#+end_src

*注意*：=sync=disabled= 提升性能但有风险，VM 内部应配置 journal。

** 场景 4: 媒体存储 (Plex/Jellyfin)

#+begin_src bash
zpool create \
  -o ashift=12 \
  -O compression=off \
  -O recordsize=1M \
  -O atime=off \
  tank raidz2 sda sdb sdc sdd sde sdf

# 媒体库
zfs create tank/media

# 自动快照 (用 zfs-auto-snapshot)
zfs set com.sun:auto-snapshot=true tank/media
#+end_src

*关键*：媒体文件已压缩，=compression=off= 避免浪费 CPU。

** 场景 5: 引导池 (可启动系统)

#+begin_src bash
# UEFI 系统
zpool create \
  -o ashift=12 \
  -o compatibility=grub2 \
  -O compression=lz4 \
  -O atime=off \
  -O xattr=sa \
  -O mountpoint=none \
  bpool mirror /dev/disk/by-id/...-part2 /dev/disk/by-id/...-part2

# 根文件系统
zfs create -o mountpoint=/ bpool/root
zfs create -o mountpoint=/home bpool/home

# 设置可引导
zpool set bootfs=bpool/root bpool
#+end_src

* 性能调优进阶

** ARC 大小调整

ZFS 默认用 *50% 的 RAM* 作为 ARC：

#+begin_src bash
# 查看当前 ARC 使用
arc_summary | grep -E "ARC size|Target size"

# 限制 ARC 大小 (例如 16GB 机器，限制 8GB)
echo "options zfs zfs_arc_max=8589934592" > /etc/modprobe.d/zfs.conf
# 8589934592 = 8 * 1024^3 字节

# 重新加载模块
modprobe -r zfs
modprobe zfs
#+end_src

*建议*：

- *桌面/笔记本*：ARC 限制到 25-30% (留内存给应用)
- *服务器*：ARC 用满 50-75%
- *数据库服务器*：ARC 限制到 20-30% (数据库自己管理缓存)

** L2ARC (二级缓存)

用 SSD 扩展 ARC：

#+begin_src bash
zpool add tank cache nvme2n1
#+end_src

*适用场景*：

- 热数据 > RAM 大小
- 随机读密集型负载 (如文件服务器)

*不适用*：

- 顺序读为主 (HDD 已经足够快)
- 写密集型 (L2ARC 只缓存读)

** ZIL/SLOG (日志设备)

用 SSD 加速同步写入：

#+begin_src bash
zpool add tank log mirror nvme2n1p1 nvme3n1p1
#+end_src

*关键*：SLOG *必须用镜像*，否则 SLOG 故障会导致池无法导入！

*性能提升*：

| 负载类型      | 无 SLOG  | 有 SLOG   | 提升    |
|-------------+--------+---------+--------|
| 数据库同步写入 | 500 ops | 8000 ops | 16x    |
| NFS 写入      | 120 MB/s | 850 MB/s | 7x     |
| 异步写入      | 无变化   | 无变化    | 0      |

** Special vdev (元数据设备)

把小文件和元数据放在 SSD 上：

#+begin_src bash
zpool add tank special mirror nvme2n1p2 nvme3n1p2

# 小于 32K 的文件存在 special vdev
zfs set special_small_blocks=32K tank
#+end_src

*效果*：

- 元数据访问延迟 10-100x 降低
- 小文件 IOPS 提升 5-10x

*警告*：special vdev 故障 = 池不可用！*必须镜像*！

* 故障排查和维护

** Scrub (数据校验)

定期 scrub 检测和修复静默损坏：

#+begin_src bash
# 手动 scrub
zpool scrub tank

# 查看进度
zpool status -v

# 停止 scrub
zpool scrub -s tank

# 自动 scrub (systemd timer)
systemctl enable zfs-scrub-monthly@tank.timer
#+end_src

*建议频率*：

- *HDD 池*：每月一次
- *SSD 池*：每周一次 (SSD 更易损坏)
- *关键数据*：每天一次 (如数据库)

** 替换故障磁盘

#+begin_src bash
# 查看池状态
zpool status tank
# pool: tank
# state: DEGRADED
# scan: scrub in progress
# config:
#   NAME        STATE     READ WRITE CKSUM
#   tank        DEGRADED     0     0     0
#     mirror-0  DEGRADED     0     0     0
#       sda     ONLINE       0     0     0
#       sdb     UNAVAIL      0     0     0  # 故障

# 离线故障磁盘
zpool offline tank sdb

# 物理替换磁盘后
zpool replace tank sdb /dev/disk/by-id/ata-NEW-DISK

# ZFS 自动 resilver (重建数据)
zpool status -v
#+end_src

** 监控工具

#+begin_src bash
# zpool iostat: 实时 I/O 统计
zpool iostat tank 1

# arc_summary: ARC 使用情况
arc_summary

# zfs list: 空间使用
zfs list -o name,used,avail,refer,mountpoint

# zpool list: 池状态
zpool list -v
#+end_src

*推荐监控工具*：

- *Prometheus + node_exporter*: 指标采集
- *Grafana*: 可视化
- *ZED (ZFS Event Daemon)*: 邮件告警

#+begin_src bash
# 配置 ZED 邮件告警
vim /etc/zfs/zed.d/zed.rc
# ZED_EMAIL_ADDR="admin@example.com"
# ZED_NOTIFY_VERBOSE=1

systemctl enable zfs-zed
systemctl start zfs-zed
#+end_src

* ZFS vs 其他文件系统

| 特性          | ZFS          | Btrfs        | XFS          | ext4         |
|-------------+-------------+-------------+-------------+-------------|
| 数据校验      | ✓ (强制)     | ✓ (可选)     | ✗            | ✗            |
| 快照          | ✓ (零成本)   | ✓ (零成本)   | ✗            | ✗            |
| 压缩          | ✓ (透明)     | ✓ (透明)     | ✗            | ✗            |
| 加密          | ✓ (原生)     | ✗            | ✗            | ✗ (LUKS)     |
| RAID          | ✓ (软件)     | ✓ (软件)     | ✗            | ✗            |
| 在线扩容      | ✓            | ✓            | ✓            | ✓ (限制)      |
| 在线缩容      | ✗            | ✓            | ✗            | ✗            |
| 去重          | ✓ (慢)       | ✓ (慢)       | ✗            | ✗            |
| 稳定性        | 优秀         | 一般         | 优秀         | 优秀         |
| 性能          | 高 (调优后)   | 中           | 高           | 中           |
| 内存占用      | 高 (ARC)     | 低           | 低           | 低           |
| 生态          | 成熟         | 发展中       | 成熟         | 成熟         |

*结论*：

- *服务器/NAS*：ZFS (数据完整性 > 一切)
- *桌面 Linux*：Btrfs (快照 + 低内存占用)
- *高性能数据库*：XFS (简单可靠)
- *嵌入式/老系统*：ext4 (兼容性最好)

* 总结: ZFS 最佳实践

** 创建池时的黄金配置

#+begin_src bash
zpool create \
  -o ashift=12 \
  -o autotrim=on \
  -o compatibility=openzfs-2.2-linux \
  -O compression=lz4 \
  -O atime=off \
  -O xattr=sa \
  -O normalization=formC \
  -O utf8only=on \
  -O relatime=on \
  tank mirror /dev/disk/by-id/ata-... /dev/disk/by-id/ata-...
#+end_src

** 永远记住的原则

1. *ashift=12*：现代硬盘的标准配置
2. *compression=lz4*：几乎零成本的 2-3x 压缩比
3. *atime=off*：除非你真的需要访问时间戳
4. *xattr=sa*：性能提升 20-50%
5. *定期 scrub*：每月至少一次
6. *监控池状态*：不要等到故障才发现问题
7. *备份*：ZFS 不是备份！RAID 不是备份！快照不是备份！

** 不要做的事

1. *不要用 RAIDZ1*：单盘容错在大容量时代不够安全，用 mirror 或 RAIDZ2
2. *不要开 dedup*：除非你有海量 RAM (1TB 数据需 5GB 内存)
3. *不要混用不同大小的盘*：RAIDZ 性能取决于最小盘
4. *不要在满池上操作*：保持 20% 空闲空间，否则碎片严重
5. *不要在生产环境用 =sync=disabled=*：数据安全 > 性能
6. *不要忘记做备份*：3-2-1 原则 (3 份副本, 2 种介质, 1 份异地)

** 推荐资源

- OpenZFS 官方文档: [[https://openzfs.github.io/openzfs-docs/]]
- Aaron Toponce 的 ZFS 教程: [[https://pthree.org/2012/04/17/install-zfs-on-debian-gnulinux/]]
- ZFS 邮件列表: [[https://github.com/openzfs/zfs/discussions]]
- FreeBSD Handbook ZFS 章节: [[https://docs.freebsd.org/en/books/handbook/zfs/]]

*最后*: ZFS 是一个强大但复杂的系统。花时间理解它的工作原理，你会得到一个 *坚如磐石* 的存储基础设施。
